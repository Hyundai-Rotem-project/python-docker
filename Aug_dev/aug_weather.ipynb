{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e8f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: albumentations in /home/hara/.local/lib/python3.10/site-packages (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/hara/.local/lib/python3.10/site-packages (from albumentations) (2.1.3)\n",
      "Requirement already satisfied: albucore==0.0.23 in /home/hara/.local/lib/python3.10/site-packages (from albumentations) (0.0.23)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/hara/.local/lib/python3.10/site-packages (from albumentations) (1.15.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /home/hara/.local/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /home/hara/.local/lib/python3.10/site-packages (from albumentations) (2.11.3)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /home/hara/.local/lib/python3.10/site-packages (from albucore==0.0.23->albumentations) (3.12.3)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /home/hara/.local/lib/python3.10/site-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/hara/.local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/hara/.local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/hara/.local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/hara/.local/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install albumentations\n",
    "%pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.61-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.2/85.2 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.41.0\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/lib/python3/dist-packages (from roboflow) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/hara/.local/lib/python3.10/site-packages (from roboflow) (2.1.3)\n",
      "Collecting pillow-heif>=0.18.0\n",
      "  Downloading pillow_heif-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python-headless==4.10.0.84\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /home/hara/.local/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from roboflow) (2020.6.20)\n",
      "Requirement already satisfied: cycler in /home/hara/.local/lib/python3.10/site-packages (from roboflow) (0.12.1)\n",
      "Collecting idna==3.7\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filetype\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting urllib3>=1.26.6\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.7/128.7 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from roboflow) (1.16.0)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests in /home/hara/.local/lib/python3.10/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /home/hara/.local/lib/python3.10/site-packages (from roboflow) (3.10.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hara/.local/lib/python3.10/site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/hara/.local/lib/python3.10/site-packages (from roboflow) (11.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hara/.local/lib/python3.10/site-packages (from matplotlib->roboflow) (4.57.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->roboflow) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hara/.local/lib/python3.10/site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hara/.local/lib/python3.10/site-packages (from matplotlib->roboflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hara/.local/lib/python3.10/site-packages (from requests->roboflow) (3.4.1)\n",
      "Installing collected packages: filetype, urllib3, tqdm, python-dotenv, pillow-heif, opencv-python-headless, idna, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.11.0.86\n",
      "    Uninstalling opencv-python-headless-4.11.0.86:\n",
      "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 requests-toolbelt-1.0.0 roboflow-1.1.61 tqdm-4.67.1 urllib3-2.4.0\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Image-Detection-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 202/202 [00:00<00:00, 277.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Image-Detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 13024.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"DLZRWqPmPgXpy0mevy0T\")\n",
    "project = rf.workspace(\"hundairotemtraining\").project(\"image-detection-dxhgd\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580d2f2",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b771f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455b32ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49135/4220190684.py:6: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n"
     ]
    }
   ],
   "source": [
    "# ì¦ê°• íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.Rotate(limit=10, p=0.3),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "    A.MotionBlur(blur_limit=5, p=0.2),\n",
    "    A.Resize(height=416, width=416),  # ì•ˆì •ì ì¸ ê³ ì • ë¦¬ì‚¬ì´ì¦ˆ\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3298e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "input_img_dir = \"./Image-Detection-1/train/images\"\n",
    "input_lbl_dir = \"./Image-Detection-1/train/labels\"\n",
    "\n",
    "# ì¦ê°•ëœ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì„ ì €ìž¥í•  ë””ë ‰í† ë¦¬\n",
    "output_img_dir = \"./Image-Detection-1/augmented_dataset/images\"\n",
    "output_lbl_dir = \"./Image-Detection-1/augmented_dataset/labels\"\n",
    "\n",
    "os.makedirs(output_img_dir, exist_ok=True)\n",
    "os.makedirs(output_lbl_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89c4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_file in os.listdir(input_img_dir):\n",
    "    if not img_file.endswith(('.jpg', '.png')):\n",
    "        continue\n",
    "\n",
    "    # ê²½ë¡œ ì¤€ë¹„\n",
    "    img_path = os.path.join(input_img_dir, img_file)\n",
    "    lbl_path = os.path.join(input_lbl_dir, img_file.rsplit('.', 1)[0] + '.txt')\n",
    "\n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    image = cv2.imread(img_path)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # ë¼ë²¨ ë¡œë“œ\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    if os.path.exists(lbl_path):\n",
    "        with open(lbl_path, 'r') as f:\n",
    "            for line in f:\n",
    "                cls, x, y, bw, bh = line.strip().split()\n",
    "                bboxes.append([float(x), float(y), float(bw), float(bh)])\n",
    "                class_labels.append(cls)\n",
    "\n",
    "    # ì¦ê°• ì ìš©\n",
    "    try:\n",
    "        augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        aug_img = augmented['image']\n",
    "        aug_bboxes = augmented['bboxes']\n",
    "        aug_labels = augmented['class_labels']\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {img_file} ì¦ê°• ì‹¤íŒ¨: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ì €ìž¥ ì´ë¦„ ë§Œë“¤ê¸°\n",
    "    base_name = img_file.rsplit('.', 1)[0]\n",
    "    aug_img_name = f\"{base_name}_aug.jpg\"\n",
    "    aug_lbl_name = f\"{base_name}_aug.txt\"\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì €ìž¥\n",
    "    cv2.imwrite(os.path.join(output_img_dir, aug_img_name), aug_img)\n",
    "\n",
    "    # ë¼ë²¨ ì €ìž¥\n",
    "    with open(os.path.join(output_lbl_dir, aug_lbl_name), 'w') as f:\n",
    "        for bbox, label in zip(aug_bboxes, aug_labels):\n",
    "            f.write(f\"{label} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1090d2e2",
   "metadata": {},
   "source": [
    "## ë‚ ì”¨, ë°°ê²½ì„ ë°”ê¾¸ëŠ” ë°ì´í„° ì¦ê°•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21ba942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.augmentations import functional as F\n",
    "import random\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "input_img_dir = \"./Image-Detection-1/train/images\"\n",
    "input_lbl_dir = \"./Image-Detection-1/train/labels\"\n",
    "\n",
    "# ì¦ê°•ëœ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸”ì„ ì €ìž¥í•  ë””ë ‰í† ë¦¬\n",
    "output_img_dir = \"./Image-Detection-1/augmented_dataset/images\"\n",
    "output_lbl_dir = \"./Image-Detection-1/augmented_dataset/labels\"\n",
    "\n",
    "os.makedirs(output_img_dir, exist_ok=True)\n",
    "os.makedirs(output_lbl_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e6817fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rain(img):\n",
    "    rain_layer = np.zeros_like(img, dtype=np.uint8)\n",
    "    for _ in range(1500):\n",
    "        x, y = np.random.randint(0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "        length = np.random.randint(10, 20)\n",
    "        cv2.line(rain_layer, (x, y), (x - 3, y + length), (200, 200, 200), 1)\n",
    "    blended = cv2.addWeighted(img, 0.8, rain_layer, 0.2, 0)\n",
    "    return blended\n",
    "\n",
    "def add_snow(img):\n",
    "    snow_layer = np.zeros_like(img, dtype=np.uint8)\n",
    "    for _ in range(2000):\n",
    "        x, y = np.random.randint(0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "        cv2.circle(snow_layer, (x, y), radius=1, color=(255, 255, 255), thickness=-1)\n",
    "    blended = cv2.addWeighted(img, 0.85, snow_layer, 0.25, 0)\n",
    "    return blended\n",
    "\n",
    "def add_wind(img):\n",
    "    blurred = cv2.GaussianBlur(img, (11, 3), sigmaX=10)\n",
    "    noise = np.random.normal(0, 5, img.shape).astype(np.uint8)\n",
    "    windy = cv2.add(blurred, noise)\n",
    "    return windy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aa30180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#âš¡ 1. ë²ˆê°œ ì¹˜ëŠ” ë‚  (Thunderstorm)\n",
    "# ì•¼ê°„ + ë°ì€ ì„¬ê´‘ íš¨ê³¼ (ëžœë¤í•œ ê°•í•œ ë°ê¸° ì˜ì—­)\n",
    "def add_thunderstorm(img):\n",
    "    img = cv2.convertScaleAbs(img, alpha=0.5, beta=-30)  # ì–´ë‘¡ê²Œ\n",
    "    mask = np.zeros_like(img, dtype=np.uint8)\n",
    "    for _ in range(2):\n",
    "        x, y = np.random.randint(0, img.shape[1]), np.random.randint(0, img.shape[0])\n",
    "        radius = np.random.randint(50, 120)\n",
    "        cv2.circle(mask, (x, y), radius, (255, 255, 255), -1)\n",
    "    lightning = cv2.addWeighted(img, 1.0, mask, 0.6, 0)\n",
    "    return lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86f501e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒ«ï¸ 2. ì•ˆê°œ ë‚€ ë‚  (Foggy)\n",
    "# ì±„ë„ë¥¼ ì¤„ì´ê³  íë¦¿í•œ ëŠë‚Œ (íë¦° ì•ŒíŒŒë¸”ë Œë”©)\n",
    "def add_fog(img):\n",
    "    fog = cv2.GaussianBlur(img, (51, 51), 0)\n",
    "    foggy = cv2.addWeighted(img, 0.6, fog, 0.4, 0)\n",
    "    return foggy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58764790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒˆ 3. ë¬´ì§€ê°œ ëœ¬ ë‚  (Rainbow)\n",
    "# í™”ë ¤í•œ ìƒ‰ìƒì˜ ì•„í¬ë¥¼ íˆ¬ëª…í•˜ê²Œ í•©ì„±\n",
    "def add_rainbow(img):\n",
    "    rainbow = np.zeros_like(img)\n",
    "    h, w = img.shape[:2]\n",
    "    center = (w // 2, h)\n",
    "    for i, color in enumerate([(255, 0, 0), (255, 127, 0), (255, 255, 0), \n",
    "                               (0, 255, 0), (0, 0, 255), (75, 0, 130), (143, 0, 255)]):\n",
    "        cv2.ellipse(rainbow, center, (int(w*0.8)-i*8, int(h*0.5)-i*8), 0, 0, 180, color, thickness=6)\n",
    "    rainbowed = cv2.addWeighted(img, 1.0, rainbow, 0.3, 0)\n",
    "    return rainbowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a3f559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒ™ 4. ë°¤í•˜ëŠ˜ (Night time)\n",
    "# ì±„ë„ì™€ ë°ê¸°ë¥¼ ì¤„ì´ê³  íŒŒëž€ ë¹›\n",
    "def add_night(img):\n",
    "    dark = cv2.convertScaleAbs(img, alpha=0.5, beta=-50)\n",
    "    night = cv2.addWeighted(dark, 1.0, np.full_like(img, (10, 10, 30)), 0.3, 0)\n",
    "    return night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34dbe9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.ðŸŒªï¸ íšŒì˜¤ë¦¬ë°”ëžŒ íš¨ê³¼ í•¨ìˆ˜\n",
    "# íšŒì˜¤ë¦¬ ë°”ëžŒì€ ì‹œê°ì ìœ¼ë¡œ ê°•í•œ ë°©ì‚¬í˜• ì™œê³¡, ì‚´ì§ì˜ íë¦¼, ê·¸ë¦¬ê³  ì•½ê°„ì˜ íšŒì „ëœ ë…¸ì´ì¦ˆ/ë¨¼ì§€ íš¨ê³¼ë¥¼ ì¡°í•©\n",
    "\n",
    "def add_tornado(img):\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # íšŒì „ ì™œê³¡ì„ ìœ„í•œ ì¢Œí‘œ ê·¸ë¦¬ë“œ ìƒì„±\n",
    "    center = (w // 2, h // 2)\n",
    "    strength = 0.0008  # íšŒì˜¤ë¦¬ ê°•ë„ (ì¡°ì ˆ ê°€ëŠ¥)\n",
    "\n",
    "    # ì¢Œí‘œ ë§µ ìƒì„±\n",
    "    map_x = np.zeros((h, w), dtype=np.float32)\n",
    "    map_y = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            dx = x - center[0]\n",
    "            dy = y - center[1]\n",
    "            r = np.sqrt(dx**2 + dy**2)\n",
    "            theta = np.arctan2(dy, dx) + strength * r\n",
    "            map_x[y, x] = center[0] + r * np.cos(theta)\n",
    "            map_y[y, x] = center[1] + r * np.sin(theta)\n",
    "\n",
    "    # íšŒì „ ì™œê³¡ ì ìš©\n",
    "    swirl = cv2.remap(img, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "\n",
    "    # ë¸”ëŸ¬ì™€ ë…¸ì´ì¦ˆë¡œ í˜„ì‹¤ê° ì¶”ê°€\n",
    "    swirl_blur = cv2.GaussianBlur(swirl, (5, 5), sigmaX=3)\n",
    "    noise = np.random.normal(0, 15, img.shape).astype(np.uint8)\n",
    "    tornado = cv2.add(swirl_blur, noise)\n",
    "\n",
    "    return tornado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdfd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.ðŸ‚ ë‚™ì—½ ë‚ ë¦¬ëŠ” íš¨ê³¼ í•¨ìˆ˜ (add_falling_leaves)\n",
    "def add_falling_leaves(img, num_leaves=30):\n",
    "    h, w = img.shape[:2]\n",
    "    leaf_img = np.zeros_like(img)\n",
    "\n",
    "    for _ in range(num_leaves):\n",
    "        # ë‚™ì—½ ìƒ‰ìƒ ëžœë¤\n",
    "        color = random.choice([(165, 42, 42), (255, 140, 0), (255, 215, 0), (139, 69, 19)])  # ê°ˆìƒ‰, ì£¼í™©, ë…¸ëž‘, ì§™ì€ ê°ˆìƒ‰\n",
    "        \n",
    "        # í¬ê¸°, ìœ„ì¹˜, íšŒì „ ê°ë„ ëžœë¤\n",
    "        center = (random.randint(0, w), random.randint(0, h))\n",
    "        size = random.randint(10, 30)\n",
    "        angle = random.uniform(0, 360)\n",
    "        \n",
    "        # íƒ€ì› ê·¸ë¦¬ê¸° (ë‚™ì—½ í˜•íƒœ)\n",
    "        # ìƒ‰ìƒì´ ëžœë¤ìž„\n",
    "        axes = (size, int(size * 0.4))\n",
    "        temp = np.zeros_like(img)\n",
    "        cv2.ellipse(temp, center, axes, angle, 0, 360, color, -1)\n",
    "\n",
    "        # ëˆ„ì \n",
    "        alpha = random.uniform(0.3, 0.7)\n",
    "        leaf_img = cv2.addWeighted(leaf_img, 1.0, temp, alpha, 0)\n",
    "\n",
    "    # ë‚™ì—½ í•©ì„±\n",
    "    result = cv2.addWeighted(img, 1.0, leaf_img, 0.4, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f39f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_transform(weather):\n",
    "    transforms = [A.Resize(640, 640)]\n",
    "    post_effect = None\n",
    "\n",
    "    if weather == 'sunny':\n",
    "        transforms.append(\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0.2, 0.5), contrast_limit=0.2, p=1.0)\n",
    "        )\n",
    "\n",
    "    elif weather == 'dark':\n",
    "        transforms.extend([\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.6, -0.3), contrast_limit=0.1, p=1.0),\n",
    "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=-30, val_shift_limit=-30, p=1.0)\n",
    "        ])\n",
    "\n",
    "    elif weather == 'sandstorm':\n",
    "        transforms.extend([\n",
    "            A.RandomBrightnessContrast(brightness_limit=(0.0, 0.1), contrast_limit=0.1, p=1.0),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=-10, p=1.0),\n",
    "            A.MotionBlur(p=0.5)\n",
    "        ])\n",
    "\n",
    "    elif weather == 'waves':\n",
    "        transforms.extend([\n",
    "            A.Blur(blur_limit=3, p=0.3),\n",
    "            A.GaussNoise(var_limit=(20.0, 50.0), p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=-20, p=1.0)\n",
    "        ])\n",
    "\n",
    "    elif weather in ['rainy', 'snowy', 'windy', 'thunderstorm', 'foggy', 'rainbow', 'night', 'tornado', 'falling_leaves']:\n",
    "        post_effect = weather  # í›„ì²˜ë¦¬ìš© í”Œëž˜ê·¸ ì„¤ì •\n",
    "\n",
    "    return A.Compose(transforms, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'])), post_effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49fdabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_types = [\n",
    "    'sunny', 'dark', 'sandstorm', 'waves',\n",
    "    'rainy', 'snowy', 'windy',\n",
    "    'thunderstorm', 'foggy', 'rainbow', 'night',\n",
    "    'tornado', 'falling_leaves'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "784a1ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12340/211686332.py:26: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(20.0, 50.0), p=0.5),\n"
     ]
    }
   ],
   "source": [
    "for img_file in os.listdir(input_img_dir):\n",
    "    if not img_file.endswith(('.jpg', '.png')):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(input_img_dir, img_file)\n",
    "    lbl_path = os.path.join(input_lbl_dir, img_file.rsplit('.', 1)[0] + '.txt')\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Resize for YOLO\n",
    "    image = cv2.resize(image, (640, 640))\n",
    "\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    if os.path.exists(lbl_path):\n",
    "        with open(lbl_path, 'r') as f:\n",
    "            for line in f:\n",
    "                cls, x, y, bw, bh = line.strip().split()\n",
    "                bboxes.append([float(x), float(y), float(bw), float(bh)])\n",
    "                class_labels.append(cls)\n",
    "\n",
    "    for weather in weather_types:\n",
    "        transform = get_weather_transform(weather)\n",
    "\n",
    "        transform, post_effect = get_weather_transform(weather)\n",
    "\n",
    "        try:\n",
    "            augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "            aug_img = augmented['image']\n",
    "            aug_bboxes = augmented['bboxes']\n",
    "            aug_labels = augmented['class_labels']\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ {img_file} {weather} ì¦ê°• ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "\n",
    "        # í›„ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        if post_effect == 'rainy':\n",
    "            aug_img = add_rain(aug_img)\n",
    "        elif post_effect == 'snowy':\n",
    "            aug_img = add_snow(aug_img)\n",
    "        elif post_effect == 'windy':\n",
    "            aug_img = add_wind(aug_img)\n",
    "        elif post_effect == 'thunderstorm':\n",
    "            aug_img = add_thunderstorm(aug_img)\n",
    "        elif post_effect == 'foggy':\n",
    "            aug_img = add_fog(aug_img)\n",
    "        elif post_effect == 'rainbow':\n",
    "            aug_img = add_rainbow(aug_img)\n",
    "        elif post_effect == 'night':\n",
    "            aug_img = add_night(aug_img)\n",
    "        elif post_effect == 'tornado':\n",
    "            aug_img = add_tornado(aug_img)\n",
    "        elif post_effect == 'falling_leaves':\n",
    "            aug_img = add_falling_leaves(aug_img)\n",
    "\n",
    "        # ì €ìž¥\n",
    "        base_name = img_file.rsplit('.', 1)[0]\n",
    "        aug_img_name = f\"{base_name}_{weather}.jpg\"\n",
    "        aug_lbl_name = f\"{base_name}_{weather}.txt\"\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_img_dir, aug_img_name), aug_img)\n",
    "\n",
    "        with open(os.path.join(output_lbl_dir, aug_lbl_name), 'w') as f:\n",
    "            for bbox, label in zip(aug_bboxes, aug_labels):\n",
    "                f.write(f\"{label} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a15f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
