{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bf24ba",
   "metadata": {},
   "source": [
    "# 딥드림\n",
    "* 합성곱 신경망이 학습한 표현을 사용하여 예술적으로 이미지를 조작하는 기법\n",
    "* 특정 필터가 아니라 전체 층의 활성화를 최대화한다.\n",
    "* 한꺼번에 많은 특성을 넣어 시각화한다.\n",
    "* 입력 이미지를 여러 다른 스케일로 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b382bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 크기: 1920 x 1080\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# 이미지 파일 경로 설정\n",
    "image_path = \"./3rd_project/test.jpg\" \n",
    "\n",
    "# 이미지 열기\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 이미지 크기 확인\n",
    "width, height = image.size\n",
    "print(f\"이미지 크기: {width} x {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d55d7315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 축소 완료: 299x299 크기로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이미지 크기 299*299로 맞추기\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 파일 경로 설정\n",
    "image_path = \"./3rd_project/test.jpg\"\n",
    "\n",
    "# 이미지 열기\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 이미지 크기를 299x299로 축소\n",
    "resized_image = image.resize((299, 299))\n",
    "# 축소된 이미지 저장\n",
    "resized_image.save(\"./3rd_project/299_test.jpg\")\n",
    "print(\"이미지 축소 완료: 299x299 크기로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b50c95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "def get_img_array(img_path, target_size):\n",
    "    # Load and preprocess the image\n",
    "    try:\n",
    "        img = keras.utils.load_img(img_path, target_size=target_size)\n",
    "        array = keras.utils.img_to_array(img)\n",
    "        array = np.expand_dims(array, axis=0)  # Adds a batch dimension\n",
    "        array = keras.applications.xception.preprocess_input(array)  # Preprocess for Xception\n",
    "        return array\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing the image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "base_image_path = \"./3rd_project/299_test.jpg\"  # Adjust your local path\n",
    "target_size = (224, 224)  # Target image size\n",
    "img_array = get_img_array(base_image_path, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f8c6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 컨브넷 사용\n",
    "# InceptionV3 모델 로드\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "\n",
    "model = inception_v3.InceptionV3(weights =\"imagenet\", include_top =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a01e124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중간층의 활성화를 반환하는 특성 추출 모델\n",
    "# 경사 상승법 단계 동안에 최대화할 손실에 대한 각 층의 기여도에 가중치를 주기 위해 스칼라 값을 선택\n",
    "\n",
    "layer_settings = {\n",
    "    \"mixed4\": 1.0,\n",
    "    \"mixed5\": 1.5,\n",
    "    \"mixed6\": 2.0,\n",
    "    \"mixed7\": 2.5,\n",
    "}\n",
    "outputs_dict = dict(\n",
    "    [\n",
    "        (layer.name, layer.output)\n",
    "        for layer in [model.get_layer(name) for name in layer_settings.keys()]\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1b83273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥드림 손실 - 각 스케일마다 최대화\n",
    "# 모든 필터 활성화를 동시에 최대화\n",
    "def compute_loss(input_image):\n",
    "    features = feature_extractor(input_image)\n",
    "    loss = tf.zeros(shape=())\n",
    "    for name in features.keys():\n",
    "        coeff = layer_settings[name]\n",
    "        activation = features[name]\n",
    "        loss += coeff * tf.reduce_mean(tf.square(activation[:, 2:-2, 2:-2, :]))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "350a8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 옥타브에서 실행할 경사 상승법법\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def gradient_ascent_step(image, learning_rate):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        loss = compute_loss(image)\n",
    "    grads = tape.gradient(loss, image)\n",
    "    grads = tf.math.l2_normalize(grads)\n",
    "    image += learning_rate * grads\n",
    "    return loss, image\n",
    "\n",
    "\n",
    "def gradient_ascent_loop(image, iterations, learning_rate, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss, image = gradient_ascent_step(image, learning_rate)\n",
    "        if max_loss is not None and loss > max_loss:\n",
    "            break\n",
    "        print(f\"... 스텝 {i}에서 손실 값: {loss:.2f}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcc0bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 50.\n",
    "num_octave = 2\n",
    "octave_scale = 1.4\n",
    "iterations = 10\n",
    "max_loss = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a29926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 처리\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = keras.utils.load_img(image_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(img):\n",
    "    img = img.reshape((img.shape[1], img.shape[2], 3))\n",
    "    img += 1.0\n",
    "    img *= 127.5\n",
    "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b2ff380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MKL(Math Kernel Library)을 활성화하도록 설정\n",
    "# MKL의 역할 : MKL은 Intel의 고성능 수학 라이브러리로, TensorFlow 연산 속도를 최적화하는 데 사용\n",
    "# 특히 CPU 기반 시스템에서 행렬 연산, 컨볼루션 등과 같은 수학적 계산을 더 빠르게 처리합니다.\n",
    "import os\n",
    "os.environ[\"TF_DISABLE_MKL\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b6f5dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213, 213) 크기의 0번째 옥타브 처리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acorn\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_933']\n",
      "Received: inputs=Tensor(shape=(1, 213, 213, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 스텝 0에서 손실 값: 1.08\n",
      "... 스텝 1에서 손실 값: 1.00\n",
      "... 스텝 2에서 손실 값: 2.56\n",
      "... 스텝 3에서 손실 값: 8.17\n",
      "(299, 299) 크기의 1번째 옥타브 처리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acorn\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_933']\n",
      "Received: inputs=Tensor(shape=(1, 299, 299, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "original_img = preprocess_image(base_image_path)\n",
    "original_shape = original_img.shape[1:3]\n",
    "\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "shrunk_original_img = tf.image.resize(original_img, successive_shapes[0])\n",
    "\n",
    "img = tf.identity(original_img)\n",
    "for i, shape in enumerate(successive_shapes):\n",
    "    print(f\"{shape} 크기의 {i}번째 옥타브 처리\")\n",
    "    img = tf.image.resize(img, shape)\n",
    "    img = gradient_ascent_loop(\n",
    "        img, iterations=iterations, learning_rate=step, max_loss=max_loss\n",
    "    )\n",
    "    upscaled_shrunk_original_img = tf.image.resize(shrunk_original_img, shape)\n",
    "    same_size_original = tf.image.resize(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = tf.image.resize(original_img, shape)\n",
    "\n",
    "keras.utils.save_img(\"./3rd_project/t1.png\", deprocess_image(img.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f03cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
